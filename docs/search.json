[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "In this project, we seek to identify both community-level sociodemographic factors and state-level funding factors that predict statewide fourth-grade achievement rates in reading. Our ultimate goal is to determine pathways for policy-based intervention in the future to maximize educational success for youth of all backgrounds. We came upon this topic as a result of the content we are learning in our FOCUS cluster, Knowledge in the Service of Society. We are seeking to go beyond identifying community-level inequities and instead hope to investigate root causes and their logical solutions. \nTo properly explore these factors, our project will include four major steps:\nFirst, we will teach ourselves how to use the maps package to create a choropleth map of the United States where a gradient scale demonstrates the state achievement rates in fourth grade reading. This visualization will allow us, and others, to easily identify the states with highest achievement rates. From here, we can conduct further analysis on the funding distributions and community-level variables in these “best-practice states.” \nSecond, we will make a second choropleth map (a map that overlays a color gradient across a geogprahic region to portray the level of another variable across locations) using the expenditures dataset. This visualization will serve as a comparison to the first one, providing a visual representation of total school expenditures in elementary schools by state. By creating two maps of the same area (the United States) and using gradient scales to indicate both funding levels and achievement scores, viewers will be able to easily draw their own conclusions about possible associations between the two factors. In later parts of our project, we will use models to come to objective standpoints. \nThird, we will use forward selection (a systematic process of adding variables to a multiple linear regression model and comparing R-squared values) to identify community-level factors (e.g. poverty rate, median household income, average cost of childcare) that accurately predict statewide fourth grade achievement rates in reading. We will select potential predictors based on background knowledge from our other FOCUS classes and then move to statistical methods (adjusted-R2) to assess their importance in this context. Ultimately, we will have a linear regression model that merges a collection of community-level socioeconomic variables to predict fourth grade reading levels. After identifying which sociodemographic changes impact education achievement, we will be able to later theorize over possible steps to progress towards overall improvement via these specific pathways.\nThe fourth goal we want to accomplish is largely based upon the initial visualizations we create. Using the choropleth map, regression model, and R-squared analysis, we will ideally identify one or two noteworthy variables that appear to be the best predictors of achievement in fourth graders. We will complete 1-3 of these three options based on initial findings.\n\nIf we see that total elementary school expenditures seems to predict achievement rate based on the choropleth map from goal #2, we will analytically confirm this relationship through linear regression. We will then use the mutate() function to see whether the relationship is maintained based on the percentage of total state funding that is spent in elementary schools or whether an association exclusively exists between the total amount of elementary school funding and achievement rates.\nBased on knowledge from our other KISS classes, we will explore the interactive effect between two significant community-level predictors of achievement rates to get a more granular understanding of how community structures combine with one another to predict academic success in youth.\nWe will determine a threshold for so-called “high achievement rates” and then subset our data to include states with achievement rates past this threshold. For these states, we will create bar charts that allow us to examine the distribution of funding in every sector within total state expenditures.\n\nWe will use these bar charts to determine which sectors (e.g. transportation, Medicaid, etc.) seem to be getting the greatest allocation of state funding in top achievement states and then use multiple linear regression to confirm our hypothesized associations between funding distribution and achievement outcomes."
  },
  {
    "objectID": "proposal.html#overview",
    "href": "proposal.html#overview",
    "title": "Proposal",
    "section": "",
    "text": "In this project, we seek to identify both community-level sociodemographic factors and state-level funding factors that predict statewide fourth-grade achievement rates in reading. Our ultimate goal is to determine pathways for policy-based intervention in the future to maximize educational success for youth of all backgrounds. We came upon this topic as a result of the content we are learning in our FOCUS cluster, Knowledge in the Service of Society. We are seeking to go beyond identifying community-level inequities and instead hope to investigate root causes and their logical solutions. \nTo properly explore these factors, our project will include four major steps:\nFirst, we will teach ourselves how to use the maps package to create a choropleth map of the United States where a gradient scale demonstrates the state achievement rates in fourth grade reading. This visualization will allow us, and others, to easily identify the states with highest achievement rates. From here, we can conduct further analysis on the funding distributions and community-level variables in these “best-practice states.” \nSecond, we will make a second choropleth map (a map that overlays a color gradient across a geogprahic region to portray the level of another variable across locations) using the expenditures dataset. This visualization will serve as a comparison to the first one, providing a visual representation of total school expenditures in elementary schools by state. By creating two maps of the same area (the United States) and using gradient scales to indicate both funding levels and achievement scores, viewers will be able to easily draw their own conclusions about possible associations between the two factors. In later parts of our project, we will use models to come to objective standpoints. \nThird, we will use forward selection (a systematic process of adding variables to a multiple linear regression model and comparing R-squared values) to identify community-level factors (e.g. poverty rate, median household income, average cost of childcare) that accurately predict statewide fourth grade achievement rates in reading. We will select potential predictors based on background knowledge from our other FOCUS classes and then move to statistical methods (adjusted-R2) to assess their importance in this context. Ultimately, we will have a linear regression model that merges a collection of community-level socioeconomic variables to predict fourth grade reading levels. After identifying which sociodemographic changes impact education achievement, we will be able to later theorize over possible steps to progress towards overall improvement via these specific pathways.\nThe fourth goal we want to accomplish is largely based upon the initial visualizations we create. Using the choropleth map, regression model, and R-squared analysis, we will ideally identify one or two noteworthy variables that appear to be the best predictors of achievement in fourth graders. We will complete 1-3 of these three options based on initial findings.\n\nIf we see that total elementary school expenditures seems to predict achievement rate based on the choropleth map from goal #2, we will analytically confirm this relationship through linear regression. We will then use the mutate() function to see whether the relationship is maintained based on the percentage of total state funding that is spent in elementary schools or whether an association exclusively exists between the total amount of elementary school funding and achievement rates.\nBased on knowledge from our other KISS classes, we will explore the interactive effect between two significant community-level predictors of achievement rates to get a more granular understanding of how community structures combine with one another to predict academic success in youth.\nWe will determine a threshold for so-called “high achievement rates” and then subset our data to include states with achievement rates past this threshold. For these states, we will create bar charts that allow us to examine the distribution of funding in every sector within total state expenditures.\n\nWe will use these bar charts to determine which sectors (e.g. transportation, Medicaid, etc.) seem to be getting the greatest allocation of state funding in top achievement states and then use multiple linear regression to confirm our hypothesized associations between funding distribution and achievement outcomes."
  },
  {
    "objectID": "proposal.html#loading-and-exploring-data",
    "href": "proposal.html#loading-and-exploring-data",
    "title": "Proposal",
    "section": "Loading and Exploring Data",
    "text": "Loading and Exploring Data\n\nlibrary(tidyverse)\n\n\n#loading dataset childcare_costs\nchildcare_costs &lt;- read_csv(\"data/childcare_costs.csv\")\n\n#loading dataset counties\ncounties &lt;- read_csv(\"data/counties.csv\")\n\n#loading dataset expenditures\nexpenditures &lt;- read_csv(\"data/expenditures.csv\")\n\n#loading dataset scores\nscores &lt;- read_csv(\"data/scores.csv\")\n\nThe expenditures dataset is sourced from the Kaiser Family Foundation, through the National Association of State Budget Officers (NASBO)’s State Expenditure Report Fiscal 2020-2022. We chose this dataset because we wanted to compare government spending by both state and sector, focusing on 2021 educational expenditure amounts and their effects upon 2022 achievement rates from the scores dataset. The expenditures dataset has 23460 observations and 6 variables. The observations are separated by state (with the additions of the District of Columbia and a row for the United States average) and specify 8 different types of public spending per state: Elementary & Secondary Education, Medicaid, Transportation, and Higher Education, Public Assistance, Corrections. \nThe scores dataset is based on the Nation’s Report Card data that uses the 2022 National Assessment of Educational Progress (NAEP) assessments with scores from 0-500 in mathematics, reading, writing, and sciences at grade 4. This dataset compares state and jurisdiction performance to the national public average scale score of 216. We chose this dataset because we need a quantitative way to analyze educational progress within each state/jurisdiction. The scores dataset has 54 observations and 6 variables. The observations are separated by state (plus the Department of Defense Education Activity, National Public, District of Columbia, and Puerto Rico). The dataset displays the average scores for each region (MN), the difference from the National Public (SigDiff), how significant the score is from the National Public (SigSymbol), the percentage at or above Basic (AB), and the percentage at or above Proficient (AP).\nThe childcare_costs dataset is from a federal source, the National Database of Childcare Prices. Measured from 2008 to 2018, its data is captured at the county level by for whom, what, where (, etc.) the childcare is provided. It also measures these data in conjunction with other seemingly unrelated variables and circumstances like teenage unemployment or young-parent labor. In the set, there are 34567 rows and 61 columns. This dataset seemed pertinent because of how deeply intertwined it is with both the basis and offshooting considerations of our project. For example, it ties childcare costs with race, location, gender, income, and more; tying these considerations in with achievement rates provides a comprehensive look at predictors for childhood success. It is our hope that this dataset provides breadth to the analyses we proceed with conducting."
  },
  {
    "objectID": "proposal.html#weekly-timeline",
    "href": "proposal.html#weekly-timeline",
    "title": "Proposal",
    "section": "Weekly Timeline:",
    "text": "Weekly Timeline:\nWeek #3 (part 1—before 11/7) \n\nFinalize write-up of high-level goal #4 - Nush \nCreate this “plan of attack” - Nush \nFinish exploring the datasets - Alan and Noah \n\nDetermine the # of observations and variables (using inline code) in each dataset\nIdentify and define the relevant variables in each dataset (using inline code) \nLoad all datasets into the project repository (3) \n\nFinalize the organization of our project repository - Julia \n\nCreate appropriate folders in the project repository with appropriate README.md files \nAdd/fix inline code in the proposal \nUpdate the data dictionary \n\nAsynchronous discussion to assign each of the outlined responsibilities to various team members \nUpload a draft of the proposal into official project repository - Nush \n\nWeek #3 (part 2—after 11/7) \n\nTeam meeting to make adjustments to our proposal following peer review \n\nWeek #4 \n\nMerge the “expenditures” dataset with “scores” dataset - Noah \nMerge the “childcarecosts” dataset with “scores” dataset - Noah\nAdapt all datasets to only include variables of interest - Noah \nRead through the description of  the “maps” package in R - Julia and Alan \n\nWork collaboratively to create two choropleth maps through the functions in the “maps” package (visualizations #1 and #2) \n\nUse forward selection to build a multiple linear regression model as outlined in goal #3 and document the process (including adjusted R2 values) - Nush \n\nWeek #5 \n\nTeam meeting: \n\nReview feedback on proposal and make adjustments to our goals accordingly \nSelect which of the options from goal #4 to pursue \nCreate a mini-timeline for the rest of the week to asynchronously achieve our finalized goal #4  \n\nFinish goal #4 as planned at team meeting \n\nWeek #6: \n\nInterpret findings and create a draft of write-up\n\nIntroduction - rationale for project and how it holistically connects to KISS - Noah\nSummary of goals and process - Noah\nFindings from visualization #1 (use inline code) - Alan \nFindings from visualization #2 (use inline code) - Alan \nFindings for visualization #3 (use inline code) - Alan\nNarrative for how we chose to approach goal #4 - Nush \nFindings from visualization(s) #4 (use inline code) - Nush \nApplications and recommendations for further research - Julia \nLimitations - Julia/Noah (depending on how long the other steps take) \n\n\nWeek #7: \n\nTeam meeting #1: \n\nFinalize write-up together \nUse write-up as an outline to design presentation \nMake adjustments to all parts of the project according to peer review\n\nTeam meeting #2: \n\nPractice and refine presentation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Loading Packages and Data",
    "section": "",
    "text": "Loading Packages and Data\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(maps)\nlibrary(leaps)\nlibrary(dplyr)\nlibrary(scales)\n\n\n#loading datasets childcare_costs and counties from tidytuesday\n\n#loading dataset childcare_costs\nchildcare_costs &lt;- read_csv(\"data/childcare_costs.csv\")\n\n#loading dataset counties\ncounties &lt;- read_csv(\"data/counties.csv\")\n\n#loading dataset expenditures\nexpenditures &lt;- read_csv(\"data/kids.csv\")\n\n#loading dataset scores\nscores &lt;- read_csv(\"data/scores.csv\")\n\n#loading us map \nus_states &lt;- map_data(\"state\")\n\n\n\nChoropleth Maps\nCode for us_states from Kieran Healy: https://socviz.co/maps.html#map-u.s.-state-level-data\n\nexpenditures_PK12ed &lt;- expenditures |&gt; \n  mutate(region = str_to_lower(state)) |&gt;\n  filter(variable == \"PK12ed\")\n\nus_states_expenditures &lt;- us_states |&gt;\n  select(-subregion) |&gt;\n  inner_join(expenditures_PK12ed, join_by(region == region), relationship = \"many-to-many\") |&gt; \n  filter(region != \"district of columbia\")\n\n\nggplot(us_states_expenditures, aes(x = long, y = lat, group = group, fill = inf_adj_perchild)) +\n  geom_polygon() +\n  theme_void() + \n  scale_fill_gradient(low = \"gray90\", high = \"darkblue\") +\n  theme(legend.position = c(.2, .1),\n        legend.direction = \"horizontal\") + \n  coord_quickmap() + \n  labs(title = \"Expenditures Based on State\", \n       fill = \"Expenditure \\nper Child \\n(in thousands)\", \n       alt = \"This visualization is a choropleth map of the United States, a plot that indicates the strength of a certain variable across different states by increasing or decreasing their shading (excluding Hawaii and Alaska). This plot has the title 'Expenditures Based on State' and is mapping state expenditures on education per child, adjusted for inflation, to each state. From this visualization, we see that states in the Northeast, namely New York and New Jersey, appear to provide the most funding to their students (at around $13,000). We can also see that states in the South and West, specifically Mississippi and Las Vegas, have the lowest expenditure per child (at around $2,500). Most of the Midwest appears to have average per child expenditures, but Wyoming stands out as having significantly greater amounts allotted towards this.\")\n\n\n\n\n\n\n\n\n\nscores_new &lt;- scores |&gt; \n  mutate(region = str_to_lower(Jurisdiction), MN = as.numeric(MN))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `MN = as.numeric(MN)`.\nCaused by warning:\n! NAs introduced by coercion\n\nus_states_scores &lt;- us_states |&gt;\n  select(-subregion) |&gt;\n  inner_join(scores_new, join_by(region == region), relationship = \"many-to-many\")\n\nggplot(us_states_scores, aes(x = long, y = lat, group = group, fill = MN)) +\n  geom_polygon() + \n  theme_void() + \n  scale_fill_gradient(low = \"gray90\", high = \"darkblue\") +\n  theme(legend.position = c(.2, .1),\n        legend.direction = \"horizontal\") + \n  coord_quickmap() + \n  labs(title = \"Achievement Rates Based on State\", \n       fill = \"Average 4th Grade \\nReading Score\",\n       alt = \"This visualization is a choropleth map of the United States, a plot that indicates the strength of a certain variable across different states by increasing or decreasing their shading (excluding Hawaii and Alaska). This plot has the title 'Achievement Rates Based on State' and is mapping 4th-grade reading achievement rates from 2022 to each state. From this visualization, we see that there does not appear to be a clear pattern in higher achievement rates--Massachusetts, New Jersey, and Florida seem to be the highest achieving states at around 225 while New Mexico and West Virginia appear to be the lowest achieving ones (at around 200). The states of Wyoming, Utah, and Colorado are also high-achieving (with scores of about 225, similarly to Massachusetts) among many other average- or low-achieving states.\")\n\n\n\n\n\n\n\n\n\n\nMerging Data\n\n#Merging childcare_costs and counties \nmerged_counties_data &lt;- left_join(childcare_costs, counties, join_by(\"county_fips_code\"))\n\n#Preparing scores to merge\nrenamed_scores &lt;- scores |&gt; \n  rename(\"state_name\" = \"Jurisdiction\")\n\n#Merging all data\nmerged_data &lt;- left_join(merged_counties_data, renamed_scores, join_by(\"state_name\"))\n\n\n\nForward Selection Approach to Linear Regression Model for Predictors of 4th Grade Reading Levels\nLiterature Review: What factors are most important in predicting elementary academic achievement levels?\nhttps://portal.ct.gov/-/media/SDE/ESSA-Evidence-Guides/Early_Skills_and_Predictors_of_Academic_Success#:~:text=Behavioral%20skills%20have%20been%20found,behavioral%20skills%20are%20developing%20appropriately.\n\nBehavioral skills, are influenced by parental monitoring and family stability\n\nSelf-regulation and social competence are two crucial behavioral skills that predict reading level\n\nLanguage minority students demonstrated more weakness in oral comprehension and vocabulary\nStudents of both genders from high-poverty households performed significantly worse in alphabet knowledge, phonological awareness, and spelling\nHigh levels of inhibitory control predicts better academic skills in Grade 1\nSocial problem-solving competence is a strong predictor of academic skills\n\nhttps://apa.org/pi/ses/resources/publications/education\n\nLow-SES families are less likely to have experiences that encourage the development of critical skills such as phonological awareness, vocabulary, and oral language\nReading competency is associated with number of books owned and parental distress\nTeachers’ years of experience and quality of training help predict children’s academic achievements\nThere is a higher likelihood of children from lower-SES households displaying learning-related behavior problems\n\nhttps://hbr.org/2023/01/how-a-parents-experience-at-work-impacts-their-kids#:~:text=A%20multi%2Dyear%20study%20following,by%20their%20parents’%20work%20lives.&text=It’s%20no%20secret%20that%20our,our%20lives%20outside%20of%20work.\n\nA longitudinal study of 370+ working-class families finds that jobs that allow for more autonomy and more supportive supervisors were warmer and more engaged with their children\nMore intimate parenting styles are associated with early academic achievement in children\nAnecdotal evidence indicates that when workers feel more trust and flexibility at work, they are more productive and better able to care for children\n\nhttps://cepa.stanford.edu/educational-opportunity-monitoring-project/achievement-gaps/race/\n\nA jarring achievement gap amongst students of varying races particularly between white, Black, and Hispanic children\n\nLikely mediated by differences in the socioeconomic statuses of families\n\n\nhttps://www.apa.org/news/press/releases/2023/06/quality-child-care-science-math#:~:text=Washington%20%E2%80%94%20Children%20who%20receive%20high,by%20the%20American%20Psychological%20Association.\n\nHigh-quality childcare has been rigorously shown to lead to better performance in science, technology, engineering, and math through high school\n\nSummarized review: After a review of literature in the field of early academic achievement, we find that various social, psychological, and economic factors have been found to contribute to the development of reading skills in elementary schoolers. Socioeconomic status has been consistently shown to influence academic success, specifically due to differing access to books, supportive services, and qualified teachers as well as due to exposure to adversity and parental distress. The structural connections between race, socioecnomic status, and long-term outcomes makes racial minority status another potential variable of interest. Along with socioeconomic status, parents’ capacity to be highly engaged and warm affects psychological health, which often underpins academic trajectories. Thus, we seek to examine whether having both, one, or no working parents affects reading skills. Finally, it is necessary to explore the role of access to both family-based and center-based child care given the proven significance of high-quality child care.\nCross-referencing research with our data to identify potential factors (most must be created using given variables):\n\nCommunity poverty level\nPercentage of community that belongs to minority racial status\nPercent of single-family households\nPercent of families where both parents work vs. where one parent works\nMedian cost of family-based childcare\nMedian cost of center-based childcare\n\n\n#Family poverty level \nmerged_data &lt;- merged_data |&gt;\n  mutate(family_poverty = pr_f)\n\n#Minority racial status \nmerged_data &lt;- merged_data |&gt; \n  mutate(\n    minority_racial_status = \n      one_race_b +\n      one_race_i +\n      one_race_a +\n      one_race_h +\n      one_race_other + \n      two_races\n  )\n\n#Percentage of single-mother households \nmerged_data &lt;- merged_data |&gt; \n  mutate(\n    percentage_single_mother =\n      h_under6_single_m / households\n  )\n  \n#Ratio of one-parent-working to two-parent-working households \nmerged_data &lt;- merged_data |&gt; \n  mutate(\n    one_parent_households = h_under6_f_work + h_under6_f_work, \n    ratio_of_one_to_both = one_parent_households / h_under6_both_work\n  )\n\n#Cost of center-based child care\nmerged_data &lt;- merged_data |&gt; \n  mutate(\n    average_center_child_care = \n    (mc_infant + mc_toddler + mc_preschool)/3\n  )\n\n#Cost of family-based child care \nmerged_data &lt;- merged_data |&gt; \n  mutate(\n    average_family_child_care = \n    (mfcc_infant + mfcc_toddler + mfcc_preschool)/3\n  )\n\n\n\nConducting Forward Selection\n\n#filtering by year \nmerged_data_2018 &lt;- merged_data |&gt; \n  filter(study_year == \"2018\")\n\n#Creating regression model with all possible variables \nmerged_data_2018 &lt;- merged_data_2018 |&gt; \n  filter(!is.na(MN),\n         !is.na(family_poverty),\n         !is.na(percentage_single_mother),\n         !is.na(ratio_of_one_to_both),\n         !is.na(average_center_child_care),\n         !is.na(average_family_child_care),\n         !is.na(one_parent_households),\n         ratio_of_one_to_both != 'Inf') |&gt;\n  mutate(\n   MN = as.numeric(MN)) \n\nmaximum_regression_model &lt;- linear_reg() |&gt;\n  fit(MN ~ family_poverty + percentage_single_mother + average_center_child_care + average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_1 &lt;- linear_reg() |&gt; \n  fit(MN ~ family_poverty, data = merged_data_2018)\n\n\n#Preparing data\nbest_states_data &lt;- merged_data_2018 |&gt; \n  arrange(desc(MN)) |&gt;\n  mutate(achievement_level = if_else(MN&gt;=223, \"High\", \"Low\")) |&gt;\n  filter(achievement_level == \"High\")\n\nbest_states_data &lt;- best_states_data |&gt;\n  relocate(state_name) |&gt; \n  pivot_longer(\n    cols = c(\"emp_m\", \"emp_service\", \"emp_sales\", \"emp_n\", \"emp_p\"), \n    names_to = \"sector_type\", \n    values_to = \"sector_percentage\"\n  ) |&gt;\n  mutate(sector_type = case_when(\n    sector_type == \"emp_m\" ~ \"Management and Science\", \n    sector_type == \"emp_n\" ~ \"Natural Resources\", \n    sector_type == \"emp_p\" ~ \"Production\", \n    sector_type == \"emp_service\" ~ \"Public Service\",\n    sector_type == \"emp_sales\" ~ \"Sales and Office\"\n    ), \n    state_name = case_when(\n      state_name == \"Massachusetts\" ~ \"MA\", \n      state_name == \"New Hampshire\" ~ \"NH\",\n      state_name == \"New Jersey\" ~ \"NJ\",\n      state_name == \"Wyoming\" ~ \"WY\"\n    )\n  )\n\n#Grouping and summarizing data \nsummarized_data &lt;- best_states_data |&gt;\n  group_by(state_name, sector_type) |&gt;\n  summarize(mean_percentage = mean(sector_percentage)) \n\n`summarise()` has grouped output by 'state_name'. You can override using the\n`.groups` argument.\n\n\n\n#Creating visualization\nggplot(summarized_data, aes(x = state_name, y = mean_percentage, fill = sector_type)) + \n  geom_bar(stat = \"identity\") + \n  scale_fill_viridis_d(option = \"G\") +\n  theme_bw() + \n  labs(title = \"Breakdown of Workplace Sectors \\n by Proportion of State Population\", x = \"State\", y = \"Percentage of Population\", fill = \"Sector\")\n\n\n\n\n\n\n\n\n\nregression_model_1 &lt;- lm(MN ~ family_poverty, data = merged_data_2018)\n\nregression_model_2 &lt;- lm(MN ~ percentage_single_mother, data = merged_data_2018)\n\nregression_model_3 &lt;- lm(MN ~ average_center_child_care, data = merged_data_2018)\n\nregression_model_4 &lt;- lm(MN ~ average_family_child_care, data = merged_data_2018)\n\nregression_model_5 &lt;- lm(MN ~ one_parent_households, data = merged_data_2018)\n\nregression_model_6 &lt;- lm(MN ~ ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_7 &lt;- lm(MN ~ family_poverty + percentage_single_mother, data = merged_data_2018)\n\nregression_model_8 &lt;- lm(MN ~ family_poverty + average_center_child_care, data = merged_data_2018)\n\nregression_model_9 &lt;- lm(MN ~ family_poverty + average_family_child_care, data = merged_data_2018)\n\nregression_model_10 &lt;- lm(MN ~ family_poverty + one_parent_households, data = merged_data_2018)\n\nregression_model_11 &lt;- lm(MN ~ family_poverty + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_12 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care, data = merged_data_2018)\n\nregression_model_13 &lt;- lm(MN ~ percentage_single_mother + average_family_child_care, data = merged_data_2018)\n\nregression_model_14 &lt;- lm(MN ~ percentage_single_mother + one_parent_households, data = merged_data_2018)\n\nregression_model_15 &lt;- lm(MN ~ percentage_single_mother + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_16 &lt;- lm(MN ~ average_center_child_care + average_family_child_care, data = merged_data_2018)\n\nregression_model_17 &lt;- lm(MN ~ average_center_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_18 &lt;- lm(MN ~ average_center_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_19 &lt;- lm(MN ~ average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_20 &lt;- lm(MN ~ average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_21 &lt;- lm(MN ~ one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_22 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care, data = merged_data_2018)\n\nregression_model_23 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_family_child_care, data = merged_data_2018)\n\nregression_model_24 &lt;- lm(MN ~ family_poverty + percentage_single_mother + one_parent_households, data = merged_data_2018)\n\nregression_model_25 &lt;- lm(MN ~ family_poverty + percentage_single_mother + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_26 &lt;- lm(MN ~ family_poverty + average_center_child_care + average_family_child_care, data = merged_data_2018)\n\nregression_model_27 &lt;- lm(MN ~ family_poverty + average_center_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_28 &lt;- lm(MN ~ family_poverty + average_center_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_29 &lt;- lm(MN ~ family_poverty + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_30 &lt;- lm(MN ~ family_poverty + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_31 &lt;- lm(MN ~ family_poverty + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_32 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + average_family_child_care, data = merged_data_2018)\n\nregression_model_33 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_34 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_35 &lt;- lm(MN ~ percentage_single_mother + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_36 &lt;- lm(MN ~ percentage_single_mother + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_37 &lt;- lm(MN ~ percentage_single_mother + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_38 &lt;- lm(MN ~ average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_39 &lt;- lm(MN ~ average_center_child_care + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_40 &lt;- lm(MN ~ average_center_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_41 &lt;- lm(MN ~ average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_42 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + average_family_child_care, data = merged_data_2018)\n\nregression_model_43 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_44 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_45 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_46 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_47 &lt;- lm(MN ~ family_poverty + percentage_single_mother + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_48 &lt;- lm(MN ~ family_poverty + average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_49 &lt;- lm(MN ~ family_poverty + average_center_child_care + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_50 &lt;- lm(MN ~ family_poverty + average_center_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_51 &lt;- lm(MN ~ family_poverty + average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_52 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_53 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_54 &lt;- lm(MN ~ percentage_single_mother + average_center_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_55 &lt;- lm(MN ~ percentage_single_mother + average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_56 &lt;- lm(MN ~ average_center_child_care + average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_57 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_58 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + average_family_child_care + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_59 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\nregression_model_60 &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_family_child_care + ratio_of_one_to_both + one_parent_households, data = merged_data_2018)\n\nregression_model_61 &lt;- lm(MN ~ family_poverty + ratio_of_one_to_both + average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nregression_model_62 &lt;- lm(MN ~ ratio_of_one_to_both + percentage_single_mother + average_center_child_care + average_family_child_care + one_parent_households, data = merged_data_2018)\n\nmaximum_regression_model &lt;- lm(MN ~ family_poverty + percentage_single_mother + average_center_child_care + average_family_child_care + one_parent_households + ratio_of_one_to_both, data = merged_data_2018)\n\ndamm &lt;- c(summary(regression_model_1)$adj.r.squared, \n          summary(regression_model_2)$adj.r.squared, \n          summary(regression_model_3)$adj.r.squared, \n          summary(regression_model_4)$adj.r.squared, \n          summary(regression_model_5)$adj.r.squared, \n          summary(regression_model_6)$adj.r.squared, \n          summary(regression_model_7)$adj.r.squared, \n          summary(regression_model_8)$adj.r.squared, \n          summary(regression_model_9)$adj.r.squared, \n          summary(regression_model_10)$adj.r.squared, \n          summary(regression_model_11)$adj.r.squared, \n          summary(regression_model_12)$adj.r.squared, \n          summary(regression_model_13)$adj.r.squared, \n          summary(regression_model_14)$adj.r.squared, \n          summary(regression_model_15)$adj.r.squared, \n          summary(regression_model_16)$adj.r.squared, \n          summary(regression_model_17)$adj.r.squared, \n          summary(regression_model_18)$adj.r.squared, \n          summary(regression_model_19)$adj.r.squared, \n          summary(regression_model_20)$adj.r.squared, \n          summary(regression_model_21)$adj.r.squared, \n          summary(regression_model_22)$adj.r.squared, \n          summary(regression_model_23)$adj.r.squared, \n          summary(regression_model_24)$adj.r.squared, \n          summary(regression_model_25)$adj.r.squared, \n          summary(regression_model_26)$adj.r.squared, \n          summary(regression_model_27)$adj.r.squared, \n          summary(regression_model_28)$adj.r.squared, \n          summary(regression_model_29)$adj.r.squared, \n          summary(regression_model_30)$adj.r.squared, \n          summary(regression_model_31)$adj.r.squared, \n          summary(regression_model_32)$adj.r.squared,\n          summary(regression_model_33)$adj.r.squared, \n          summary(regression_model_34)$adj.r.squared, \n          summary(regression_model_35)$adj.r.squared, \n          summary(regression_model_36)$adj.r.squared, \n          summary(regression_model_37)$adj.r.squared, \n          summary(regression_model_38)$adj.r.squared, \n          summary(regression_model_39)$adj.r.squared, \n          summary(regression_model_40)$adj.r.squared, \n          summary(regression_model_41)$adj.r.squared, \n          summary(regression_model_42)$adj.r.squared, \n          summary(regression_model_43)$adj.r.squared, \n          summary(regression_model_44)$adj.r.squared, \n          summary(regression_model_45)$adj.r.squared, \n          summary(regression_model_46)$adj.r.squared, \n          summary(regression_model_47)$adj.r.squared, \n          summary(regression_model_48)$adj.r.squared,\n          summary(regression_model_49)$adj.r.squared, \n          summary(regression_model_50)$adj.r.squared, \n          summary(regression_model_51)$adj.r.squared, \n          summary(regression_model_52)$adj.r.squared, \n          summary(regression_model_53)$adj.r.squared, \n          summary(regression_model_54)$adj.r.squared, \n          summary(regression_model_55)$adj.r.squared, \n          summary(regression_model_56)$adj.r.squared, \n          summary(regression_model_57)$adj.r.squared, \n          summary(regression_model_58)$adj.r.squared, \n          summary(regression_model_59)$adj.r.squared, \n          summary(regression_model_60)$adj.r.squared, \n          summary(regression_model_61)$adj.r.squared, \n          summary(regression_model_62)$adj.r.squared, \n          summary(maximum_regression_model)$adj.r.squared)\n\nfinal &lt;- as.data.frame(damm)\n\nmax_r_squared &lt;- max(final)\n\nfinal\n\n            damm\n1   0.0283969992\n2   0.0078662541\n3   0.0209201135\n4   0.0345549131\n5  -0.0002316436\n6   0.0123083188\n7   0.0289617701\n8   0.0347044837\n9   0.0451799388\n10  0.0280173249\n11  0.0348051562\n12  0.0242700816\n13  0.0374879150\n14  0.0078191515\n15  0.0185182968\n16  0.0382142287\n17  0.0219529320\n18  0.0291475743\n19  0.0365071509\n20  0.0432552210\n21  0.0121112559\n22  0.0348046624\n23  0.0450274331\n24  0.0285504918\n25  0.0351265017\n26  0.0517708597\n27  0.0348988680\n28  0.0402145464\n29  0.0463187434\n30  0.0510753576\n31  0.0344483941\n32  0.0421108572\n33  0.0247291338\n34  0.0318603155\n35  0.0388110991\n36  0.0454546633\n37  0.0184913051\n38  0.0394909330\n39  0.0489061451\n40  0.0297825603\n41  0.0448413115\n42  0.0516288182\n43  0.0351113955\n44  0.0401751925\n45  0.0462952826\n46  0.0508162511\n47  0.0347305700\n48  0.0521348100\n49  0.0593723228\n50  0.0402483434\n51  0.0520493663\n52  0.0427279519\n53  0.0520635638\n54  0.0320617008\n55  0.0465393686\n56  0.0497112269\n57  0.0520834600\n58  0.0591105617\n59  0.0402929462\n60  0.0518864597\n61  0.0595349569\n62  0.0523723338\n63  0.0593321773"
  },
  {
    "objectID": "proposal.html#repository-organization",
    "href": "proposal.html#repository-organization",
    "title": "Proposal",
    "section": "Repository Organization:",
    "text": "Repository Organization:\nOur repository is organized in a simple yet effective manner. All data files have been loaded into the data folder as csv files with a corresponding data dictionary in the README.md in the folder. Quarto files and the project itself have been left in the first level of the repository so that they have easy access to the data files and other objects."
  }
]